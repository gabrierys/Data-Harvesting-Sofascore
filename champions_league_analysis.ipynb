{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a7b57e",
   "metadata": {},
   "source": [
    "<img src='https://www.unifor.br/o/unifor-theme/images/unifor-logo-horizontal.svg' width=\"250px\">\n",
    "\n",
    "# DATA HARVESTING / Projeto da Disciplina\n",
    "\n",
    "Prof.: Ms. Alex Lima<br>\n",
    "MBA em Ciência de Dados<br>\n",
    "Universidade de Fortaleza\n",
    "\n",
    "**Gabriela Ferreira Coutinho - 2418581**</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19908afc",
   "metadata": {},
   "source": [
    "# 1. Capturando as URLs para Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2aeba",
   "metadata": {},
   "source": [
    "## 1.1 Instalação e Configuração "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f037b4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selenium configurado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# 🔹 Configuração do Selenium para evitar bloqueios\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\")\n",
    "\n",
    "# 🔹 Inicializa o WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "print(\"✅ Selenium configurado com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2df57",
   "metadata": {},
   "source": [
    "## 1.2 Acessar a Página Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "372707bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Página carregada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 🔹 URL da página principal do torneio\n",
    "url_base = \"https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7\"\n",
    "driver.get(url_base)\n",
    "\n",
    "# 🔹 Espera a página carregar totalmente\n",
    "WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "time.sleep(5)  # Tempo extra para garantir carregamento\n",
    "\n",
    "print(\"✅ Página carregada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9218ac9",
   "metadata": {},
   "source": [
    "## 1.3 Abrir o Dropdown e Coletar as Temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ad0109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temporadas coletadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Clicar no botão do dropdown para abrir a lista de temporadas\n",
    "try:\n",
    "    dropdown_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CLASS_NAME, \"DropdownButton\"))\n",
    "    )\n",
    "    dropdown_button.click()\n",
    "    time.sleep(3)  # Espera os itens carregarem\n",
    "except Exception as e:\n",
    "    print(\"🚨 Erro ao abrir o dropdown das temporadas:\", e)\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# 🔹 Coletar os IDs das temporadas\n",
    "temporadas_urls = {}\n",
    "\n",
    "try:\n",
    "    # 🔹 Buscar a lista de temporadas toda vez antes de interagir\n",
    "    temporadas_elements = driver.find_elements(By.XPATH, \"//ul[@role='listbox']/li\")\n",
    "    temporadas_textos = [item.text.strip() for item in temporadas_elements]\n",
    "\n",
    "    for nome_temporada in temporadas_textos:\n",
    "        # 🔹 Reabre o dropdown para garantir que ele ainda está disponível\n",
    "        dropdown_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"DropdownButton\"))\n",
    "        )\n",
    "        dropdown_button.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 🔹 Rebusca a lista de temporadas antes de clicar\n",
    "        temporadas_elements = driver.find_elements(By.XPATH, \"//ul[@role='listbox']/li\")\n",
    "\n",
    "        for item in temporadas_elements:\n",
    "            if item.text.strip() == nome_temporada:\n",
    "                item.click()  # Seleciona a temporada para carregar a página correta\n",
    "                time.sleep(3)\n",
    "\n",
    "                # 🔹 Coletar o ID da URL após a seleção\n",
    "                temporada_id = driver.current_url.split(\"#id:\")[-1]\n",
    "                url_final = f\"https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:{temporada_id}\"\n",
    "                temporadas_urls[nome_temporada] = url_final\n",
    "                break\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"🚨 Erro ao coletar as temporadas:\", e)\n",
    "\n",
    "print(\"✅ Temporadas coletadas com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58673a",
   "metadata": {},
   "source": [
    "## 1.4 Mostrar as 10 Temporadas Coletadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86ec29b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Temporadas encontradas no Sofascore:\n",
      "23/24: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:52162\n",
      "22/23: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:41897\n",
      "21/22: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:36886\n",
      "20/21: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:29267\n",
      "19/20: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:23766\n",
      "18/19: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:17351\n",
      "17/18: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:13415\n",
      "16/17: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:11773\n",
      "15/16: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:10390\n",
      "14/15: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:8226\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Filtrar apenas as 10 últimas temporadas\n",
    "temporadas_filtradas = dict(list(temporadas_urls.items())[:10])\n",
    "\n",
    "# 🔹 Exibe os IDs e URLs corrigidas\n",
    "print(\"\\n📌 Temporadas encontradas no Sofascore:\")\n",
    "for temporada, url in temporadas_filtradas.items():\n",
    "    print(f\"{temporada}: {url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2559f79",
   "metadata": {},
   "source": [
    "## 1.5 Fechar o navegador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c3bb007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Navegador fechado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Fechar o navegador ao fim do processo\n",
    "driver.quit()\n",
    "print(\"✅ Navegador fechado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd468808",
   "metadata": {},
   "source": [
    "## 1.6 Salvar temporadas como CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00cd6c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Temporadas salvas em data/temporadas_urls.csv!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 🔹 Criar a pasta 'data' caso não exista\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# 🔹 Caminho do arquivo CSV\n",
    "csv_path = \"data/temporadas_urls.csv\"\n",
    "\n",
    "# 🔹 Converter dicionário para DataFrame e salvar\n",
    "df_temporadas = pd.DataFrame(list(temporadas_filtradas.items()), columns=[\"Temporada\", \"URL\"])\n",
    "df_temporadas.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✅ Temporadas salvas em {csv_path}!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3599f",
   "metadata": {},
   "source": [
    "# 2. Capturar dados dos jogadores das temporadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419a9f8",
   "metadata": {},
   "source": [
    "## 2.1 Carregar as Temporadas do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad22e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 10 temporadas carregadas do CSV para scraping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 🔹 Caminho do arquivo CSV salvo anteriormente\n",
    "csv_path = \"data/temporadas_urls.csv\"\n",
    "\n",
    "# 🔹 Carregar o CSV e transformar em dicionário {Temporada: URL}\n",
    "df_temporadas = pd.read_csv(csv_path)\n",
    "temporadas_urls = dict(zip(df_temporadas[\"Temporada\"], df_temporadas[\"URL\"]))\n",
    "\n",
    "print(f\"✅ {len(temporadas_urls)} temporadas carregadas do CSV para scraping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce0fd4",
   "metadata": {},
   "source": [
    "## 2.2 Função para Coletar Dados de uma Temporada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c9b31",
   "metadata": {},
   "source": [
    "### 2.2.1 Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aae81d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuração inicial concluída!\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Importação das bibliotecas necessárias\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 🔹 Configuração do Selenium para evitar bloqueios\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\")\n",
    "\n",
    "# 🔹 Inicializa o WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# 🔹 Criar a pasta \"data\" para armazenar os resultados\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "print(\"✅ Configuração inicial concluída!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d4a8a",
   "metadata": {},
   "source": [
    "### 2.2.2 Carregar Temporadas do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a3076a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 10 temporadas carregadas do CSV para scraping.\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Carregar as URLs das temporadas do arquivo CSV\n",
    "csv_path = \"data/temporadas_urls.csv\"\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    df_temporadas = pd.read_csv(csv_path)\n",
    "    temporadas_urls = dict(zip(df_temporadas[\"Temporada\"], df_temporadas[\"URL\"]))\n",
    "    print(f\"✅ {len(temporadas_urls)} temporadas carregadas do CSV para scraping.\")\n",
    "else:\n",
    "    print(\"❌ Arquivo de temporadas não encontrado. Execute a etapa de coleta de URLs primeiro!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922e564",
   "metadata": {},
   "source": [
    "### 2.2.3 Função para Coletar Estatísticas dos Jogadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cc5e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coletar_dados_temporada(temporada, url):\n",
    "    print(f\"\\n🔄 Acessando temporada {temporada}: {url}\")\n",
    "\n",
    "    # Inicializa as variáveis antes do scraping\n",
    "    dados_totais = []\n",
    "    cabecalhos = []\n",
    "\n",
    "    # 🟢 **1º Passo: Coletar a primeira página com Requests + BeautifulSoup**\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        tabela = soup.find(\"table\")\n",
    "\n",
    "        if tabela:\n",
    "            print(\"✅ Tabela encontrada com BeautifulSoup\")\n",
    "\n",
    "            # Captura os cabeçalhos da tabela\n",
    "            cabecalhos = [th.text.strip() for th in tabela.find_all(\"th\")]\n",
    "            cabecalhos.insert(1, \"Time\")  # Adiciona a coluna \"Time\"\n",
    "\n",
    "            # Captura os dados da primeira página\n",
    "            for linha in tabela.find_all(\"tr\")[1:]:\n",
    "                colunas = linha.find_all(\"td\")\n",
    "                if colunas:\n",
    "                    try:\n",
    "                        time_element = colunas[1].find(\"img\")\n",
    "                        nome_time = time_element[\"alt\"] if time_element else \"Desconhecido\"\n",
    "                    except:\n",
    "                        nome_time = \"Desconhecido\"\n",
    "\n",
    "                    dados_linha = [coluna.text.strip() for coluna in colunas]\n",
    "                    dados_linha.insert(1, nome_time)\n",
    "                    dados_totais.append(dados_linha)\n",
    "\n",
    "            print(\"✅ Dados da primeira página coletados com Requests + BeautifulSoup\")\n",
    "        else:\n",
    "            print(\"⚠️ Tabela não encontrada com Requests, tentando Selenium...\")\n",
    "\n",
    "    else:\n",
    "        print(f\"⚠️ Erro ao carregar a página ({response.status_code}), tentando Selenium...\")\n",
    "\n",
    "    # 🟡 **2º Passo: Coletar as próximas páginas com Selenium**\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                tabela = driver.find_element(By.TAG_NAME, \"table\")\n",
    "\n",
    "                # Capturar cabeçalhos apenas se não foram definidos antes\n",
    "                if not cabecalhos:\n",
    "                    cabecalhos = [th.text for th in tabela.find_elements(By.TAG_NAME, \"th\")]\n",
    "                    cabecalhos.insert(1, \"Time\")\n",
    "\n",
    "                # Capturar os dados das páginas\n",
    "                linhas = tabela.find_elements(By.TAG_NAME, \"tr\")\n",
    "                for linha in linhas[1:]:\n",
    "                    colunas = linha.find_elements(By.TAG_NAME, \"td\")\n",
    "                    if colunas:\n",
    "                        try:\n",
    "                            time_element = colunas[1].find_element(By.TAG_NAME, \"img\")\n",
    "                            nome_time = time_element.get_attribute(\"alt\") if time_element else \"Desconhecido\"\n",
    "                        except:\n",
    "                            nome_time = \"Desconhecido\"\n",
    "\n",
    "                        dados_linha = [coluna.text for coluna in colunas]\n",
    "                        dados_linha.insert(1, nome_time)\n",
    "                        dados_totais.append(dados_linha)\n",
    "\n",
    "                # Verificar o botão de próxima página\n",
    "                try:\n",
    "                    botao_proximo = WebDriverWait(driver, 5).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@style, 'justify-content: flex-end')]\"))\n",
    "                    )\n",
    "                    if \"disabled\" in botao_proximo.get_attribute(\"class\"):\n",
    "                        break\n",
    "\n",
    "                    botao_proximo.click()\n",
    "                    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "                except:\n",
    "                    print(\"📌 Última página alcançada.\")\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erro ao capturar dados da temporada {temporada}: {e}\")\n",
    "                break\n",
    "\n",
    "        # **Salvar os dados em CSV**\n",
    "        if dados_totais:\n",
    "            df = pd.DataFrame(dados_totais, columns=cabecalhos)\n",
    "            nome_arquivo = f\"data/estatisticas_jogadores_{temporada.replace('/', '-')}.csv\"\n",
    "            df.to_csv(nome_arquivo, index=False, encoding=\"utf-8\")\n",
    "            print(f\"✅ Dados da temporada {temporada} salvos em {nome_arquivo}\")\n",
    "        else:\n",
    "            print(f\"❌ Nenhum dado foi coletado para a temporada {temporada}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"🚨 Erro ao carregar a página da temporada {temporada}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a47f8a",
   "metadata": {},
   "source": [
    "### 2.2.4 Executar Web Scraping para Todas as Temporadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f69c52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Acessando temporada 23/24: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:52162\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 23/24 salvos em data/estatisticas_jogadores_23-24.csv\n",
      "\n",
      "🔄 Acessando temporada 22/23: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:41897\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 22/23 salvos em data/estatisticas_jogadores_22-23.csv\n",
      "\n",
      "🔄 Acessando temporada 21/22: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:36886\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 21/22 salvos em data/estatisticas_jogadores_21-22.csv\n",
      "\n",
      "🔄 Acessando temporada 20/21: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:29267\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 20/21 salvos em data/estatisticas_jogadores_20-21.csv\n",
      "\n",
      "🔄 Acessando temporada 19/20: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:23766\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 19/20 salvos em data/estatisticas_jogadores_19-20.csv\n",
      "\n",
      "🔄 Acessando temporada 18/19: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:17351\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 18/19 salvos em data/estatisticas_jogadores_18-19.csv\n",
      "\n",
      "🔄 Acessando temporada 17/18: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:13415\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 17/18 salvos em data/estatisticas_jogadores_17-18.csv\n",
      "\n",
      "🔄 Acessando temporada 16/17: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:11773\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 16/17 salvos em data/estatisticas_jogadores_16-17.csv\n",
      "\n",
      "🔄 Acessando temporada 15/16: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:10390\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 15/16 salvos em data/estatisticas_jogadores_15-16.csv\n",
      "\n",
      "🔄 Acessando temporada 14/15: https://www.sofascore.com/pt/torneio/futebol/europe/uefa-champions-league/7#id:8226\n",
      "⚠️ Tabela não encontrada com Requests, tentando Selenium...\n",
      "📌 Última página alcançada.\n",
      "✅ Dados da temporada 14/15 salvos em data/estatisticas_jogadores_14-15.csv\n",
      "✅ Web scraping concluído! Navegador fechado.\n"
     ]
    }
   ],
   "source": [
    "# 🔹 Executar a coleta de estatísticas para todas as temporadas\n",
    "for temporada, url in temporadas_urls.items():\n",
    "    coletar_dados_temporada(temporada, url)\n",
    "\n",
    "# 🔹 Fechar o navegador ao final do processo\n",
    "driver.quit()\n",
    "print(\"✅ Web scraping concluído! Navegador fechado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
